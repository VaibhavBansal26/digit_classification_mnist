{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efcc88a8-7284-47cb-bcb2-da70ce475b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# Create model with two hidden layers and an output layer\n",
    "def create_multilayer_perceptron():\n",
    "    # Network Parameters\n",
    "    n_hidden_1 = 256  # 1st layer number of features\n",
    "    n_hidden_2 = 256  # 2nd layer number of features\n",
    "    n_input = 2376    # data input\n",
    "    n_classes = 2     # number of classes\n",
    "\n",
    "    # Define the input layer\n",
    "    x = tf.keras.Input(shape=(n_input,))\n",
    "\n",
    "    # Hidden layers with ReLU activation\n",
    "    layer_1 = tf.keras.layers.Dense(n_hidden_1, activation='relu')(x)\n",
    "    layer_2 = tf.keras.layers.Dense(n_hidden_2, activation='relu')(layer_1)\n",
    "\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.keras.layers.Dense(n_classes)(layer_2)\n",
    "\n",
    "    # Create the model\n",
    "    model = tf.keras.Model(inputs=x, outputs=out_layer)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26a09927-09ff-4cfe-87d1-2ba1c3b2d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    with open('basecode/face_all.pickle', 'rb') as file:\n",
    "        pickle_obj = pickle.load(file)\n",
    "    features = pickle_obj['Features']\n",
    "    labels = pickle_obj['Labels']\n",
    "    train_x = features[0:21100] / 255\n",
    "    valid_x = features[21100:23765] / 255\n",
    "    test_x = features[23765:] / 255\n",
    "\n",
    "    labels = labels.T\n",
    "    train_y = np.zeros(shape=(21100, 2))\n",
    "    train_l = labels[0:21100]\n",
    "    valid_y = np.zeros(shape=(2665, 2))\n",
    "    valid_l = labels[21100:23765]\n",
    "    test_y = np.zeros(shape=(2642, 2))\n",
    "    test_l = labels[23765:]\n",
    "    for i in range(train_y.shape[0]):\n",
    "        train_y[i, train_l[i]] = 1\n",
    "    for i in range(valid_y.shape[0]):\n",
    "        valid_y[i, valid_l[i]] = 1\n",
    "    for i in range(test_y.shape[0]):\n",
    "        test_y[i, test_l[i]] = 1\n",
    "\n",
    "    return train_x, train_y, valid_x, valid_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bad0940-d5de-487f-94fc-12872de63caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.6916 - loss: 0.5776 - val_accuracy: 0.8045 - val_loss: 0.4404\n",
      "Epoch 2/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8263 - loss: 0.4094 - val_accuracy: 0.8289 - val_loss: 0.3881\n",
      "Epoch 3/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8418 - loss: 0.3642 - val_accuracy: 0.8548 - val_loss: 0.3530\n",
      "Epoch 4/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8549 - loss: 0.3381 - val_accuracy: 0.8638 - val_loss: 0.3355\n",
      "Epoch 5/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8664 - loss: 0.3167 - val_accuracy: 0.8683 - val_loss: 0.3219\n",
      "Epoch 6/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8704 - loss: 0.3081 - val_accuracy: 0.8735 - val_loss: 0.3123\n",
      "Epoch 7/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8738 - loss: 0.2959 - val_accuracy: 0.8765 - val_loss: 0.3149\n",
      "Epoch 8/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8773 - loss: 0.2928 - val_accuracy: 0.8803 - val_loss: 0.2945\n",
      "Epoch 9/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8863 - loss: 0.2742 - val_accuracy: 0.8717 - val_loss: 0.3037\n",
      "Epoch 10/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8806 - loss: 0.2801 - val_accuracy: 0.8871 - val_loss: 0.2876\n",
      "Epoch 11/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8895 - loss: 0.2607 - val_accuracy: 0.8308 - val_loss: 0.3736\n",
      "Epoch 12/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8928 - loss: 0.2598 - val_accuracy: 0.8713 - val_loss: 0.3092\n",
      "Epoch 13/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8844 - loss: 0.2697 - val_accuracy: 0.8897 - val_loss: 0.2838\n",
      "Epoch 14/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8994 - loss: 0.2433 - val_accuracy: 0.8833 - val_loss: 0.2887\n",
      "Epoch 15/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8980 - loss: 0.2436 - val_accuracy: 0.8916 - val_loss: 0.2743\n",
      "Epoch 16/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9001 - loss: 0.2431 - val_accuracy: 0.8826 - val_loss: 0.3051\n",
      "Epoch 17/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9058 - loss: 0.2339 - val_accuracy: 0.8822 - val_loss: 0.2928\n",
      "Epoch 18/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9031 - loss: 0.2293 - val_accuracy: 0.8878 - val_loss: 0.2766\n",
      "Epoch 19/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9095 - loss: 0.2224 - val_accuracy: 0.8916 - val_loss: 0.2773\n",
      "Epoch 20/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9144 - loss: 0.2158 - val_accuracy: 0.8867 - val_loss: 0.2792\n",
      "Epoch 21/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9086 - loss: 0.2227 - val_accuracy: 0.8882 - val_loss: 0.2800\n",
      "Epoch 22/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9119 - loss: 0.2175 - val_accuracy: 0.8878 - val_loss: 0.2853\n",
      "Epoch 23/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9146 - loss: 0.2085 - val_accuracy: 0.8818 - val_loss: 0.2871\n",
      "Epoch 24/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9212 - loss: 0.1980 - val_accuracy: 0.8841 - val_loss: 0.2911\n",
      "Epoch 25/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9157 - loss: 0.2069 - val_accuracy: 0.8735 - val_loss: 0.3278\n",
      "Epoch 26/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9176 - loss: 0.2062 - val_accuracy: 0.8747 - val_loss: 0.2974\n",
      "Epoch 27/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9215 - loss: 0.1935 - val_accuracy: 0.8912 - val_loss: 0.2865\n",
      "Epoch 28/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9228 - loss: 0.1956 - val_accuracy: 0.8916 - val_loss: 0.2895\n",
      "Epoch 29/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9268 - loss: 0.1871 - val_accuracy: 0.8856 - val_loss: 0.2997\n",
      "Epoch 30/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9289 - loss: 0.1785 - val_accuracy: 0.8803 - val_loss: 0.2920\n",
      "Epoch 31/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9339 - loss: 0.1707 - val_accuracy: 0.8623 - val_loss: 0.3415\n",
      "Epoch 32/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9307 - loss: 0.1755 - val_accuracy: 0.8904 - val_loss: 0.2910\n",
      "Epoch 33/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9419 - loss: 0.1561 - val_accuracy: 0.8856 - val_loss: 0.2928\n",
      "Epoch 34/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9382 - loss: 0.1607 - val_accuracy: 0.8653 - val_loss: 0.3354\n",
      "Epoch 35/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9367 - loss: 0.1589 - val_accuracy: 0.8811 - val_loss: 0.3199\n",
      "Epoch 36/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9379 - loss: 0.1608 - val_accuracy: 0.8908 - val_loss: 0.2932\n",
      "Epoch 37/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9453 - loss: 0.1451 - val_accuracy: 0.8811 - val_loss: 0.3122\n",
      "Epoch 38/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9453 - loss: 0.1485 - val_accuracy: 0.8852 - val_loss: 0.3155\n",
      "Epoch 39/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9541 - loss: 0.1267 - val_accuracy: 0.8867 - val_loss: 0.3126\n",
      "Epoch 40/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9485 - loss: 0.1393 - val_accuracy: 0.8765 - val_loss: 0.3414\n",
      "Epoch 41/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9527 - loss: 0.1257 - val_accuracy: 0.8803 - val_loss: 0.3227\n",
      "Epoch 42/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9499 - loss: 0.1336 - val_accuracy: 0.8608 - val_loss: 0.3861\n",
      "Epoch 43/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9437 - loss: 0.1402 - val_accuracy: 0.8604 - val_loss: 0.3753\n",
      "Epoch 44/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9562 - loss: 0.1204 - val_accuracy: 0.8874 - val_loss: 0.3198\n",
      "Epoch 45/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9587 - loss: 0.1162 - val_accuracy: 0.8893 - val_loss: 0.3251\n",
      "Epoch 46/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9618 - loss: 0.1079 - val_accuracy: 0.8859 - val_loss: 0.3262\n",
      "Epoch 47/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9610 - loss: 0.1093 - val_accuracy: 0.8660 - val_loss: 0.3887\n",
      "Epoch 48/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9587 - loss: 0.1154 - val_accuracy: 0.8788 - val_loss: 0.3458\n",
      "Epoch 49/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9583 - loss: 0.1103 - val_accuracy: 0.8818 - val_loss: 0.3403\n",
      "Epoch 50/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9633 - loss: 0.1021 - val_accuracy: 0.8889 - val_loss: 0.3282\n",
      "Epoch 51/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9632 - loss: 0.0989 - val_accuracy: 0.8863 - val_loss: 0.3505\n",
      "Epoch 52/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9648 - loss: 0.0992 - val_accuracy: 0.8837 - val_loss: 0.3640\n",
      "Epoch 53/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9712 - loss: 0.0896 - val_accuracy: 0.8886 - val_loss: 0.3525\n",
      "Epoch 54/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9665 - loss: 0.0953 - val_accuracy: 0.8874 - val_loss: 0.3701\n",
      "Epoch 55/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9712 - loss: 0.0839 - val_accuracy: 0.8811 - val_loss: 0.3802\n",
      "Epoch 56/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9706 - loss: 0.0884 - val_accuracy: 0.8443 - val_loss: 0.4684\n",
      "Epoch 57/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9696 - loss: 0.0880 - val_accuracy: 0.8552 - val_loss: 0.4557\n",
      "Epoch 58/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9644 - loss: 0.0914 - val_accuracy: 0.8792 - val_loss: 0.3813\n",
      "Epoch 59/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9728 - loss: 0.0775 - val_accuracy: 0.8799 - val_loss: 0.3799\n",
      "Epoch 60/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9765 - loss: 0.0706 - val_accuracy: 0.8777 - val_loss: 0.4185\n",
      "Epoch 61/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9684 - loss: 0.0859 - val_accuracy: 0.8882 - val_loss: 0.3918\n",
      "Epoch 62/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9747 - loss: 0.0755 - val_accuracy: 0.8773 - val_loss: 0.3975\n",
      "Epoch 63/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9761 - loss: 0.0728 - val_accuracy: 0.8266 - val_loss: 0.5569\n",
      "Epoch 64/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9706 - loss: 0.0809 - val_accuracy: 0.8886 - val_loss: 0.4135\n",
      "Epoch 65/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9812 - loss: 0.0585 - val_accuracy: 0.8702 - val_loss: 0.4377\n",
      "Epoch 66/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9712 - loss: 0.0766 - val_accuracy: 0.8675 - val_loss: 0.4748\n",
      "Epoch 67/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9736 - loss: 0.0709 - val_accuracy: 0.8559 - val_loss: 0.4914\n",
      "Epoch 68/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9791 - loss: 0.0658 - val_accuracy: 0.8878 - val_loss: 0.4304\n",
      "Epoch 69/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9807 - loss: 0.0582 - val_accuracy: 0.8728 - val_loss: 0.4428\n",
      "Epoch 70/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9775 - loss: 0.0621 - val_accuracy: 0.8833 - val_loss: 0.4238\n",
      "Epoch 71/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9825 - loss: 0.0536 - val_accuracy: 0.8859 - val_loss: 0.4377\n",
      "Epoch 72/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9843 - loss: 0.0507 - val_accuracy: 0.8822 - val_loss: 0.4371\n",
      "Epoch 73/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9704 - loss: 0.0717 - val_accuracy: 0.8765 - val_loss: 0.4912\n",
      "Epoch 74/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9783 - loss: 0.0604 - val_accuracy: 0.8811 - val_loss: 0.4598\n",
      "Epoch 75/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9795 - loss: 0.0599 - val_accuracy: 0.8780 - val_loss: 0.5139\n",
      "Epoch 76/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9757 - loss: 0.0693 - val_accuracy: 0.8814 - val_loss: 0.4530\n",
      "Epoch 77/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9862 - loss: 0.0443 - val_accuracy: 0.8630 - val_loss: 0.5385\n",
      "Epoch 78/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0652 - val_accuracy: 0.8814 - val_loss: 0.4700\n",
      "Epoch 79/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9880 - loss: 0.0395 - val_accuracy: 0.8720 - val_loss: 0.5027\n",
      "Epoch 80/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9838 - loss: 0.0486 - val_accuracy: 0.8769 - val_loss: 0.5249\n",
      "Epoch 81/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9843 - loss: 0.0474 - val_accuracy: 0.8837 - val_loss: 0.4819\n",
      "Epoch 82/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9885 - loss: 0.0381 - val_accuracy: 0.8837 - val_loss: 0.4834\n",
      "Epoch 83/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9825 - loss: 0.0477 - val_accuracy: 0.8841 - val_loss: 0.4926\n",
      "Epoch 84/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9779 - loss: 0.0590 - val_accuracy: 0.8803 - val_loss: 0.5123\n",
      "Epoch 85/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9877 - loss: 0.0392 - val_accuracy: 0.8792 - val_loss: 0.5017\n",
      "Epoch 86/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9894 - loss: 0.0339 - val_accuracy: 0.8833 - val_loss: 0.5026\n",
      "Epoch 87/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9919 - loss: 0.0311 - val_accuracy: 0.8619 - val_loss: 0.5802\n",
      "Epoch 88/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9828 - loss: 0.0454 - val_accuracy: 0.8672 - val_loss: 0.5766\n",
      "Epoch 89/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9832 - loss: 0.0477 - val_accuracy: 0.8844 - val_loss: 0.5341\n",
      "Epoch 90/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9905 - loss: 0.0337 - val_accuracy: 0.8780 - val_loss: 0.5418\n",
      "Epoch 91/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9916 - loss: 0.0302 - val_accuracy: 0.8769 - val_loss: 0.5341\n",
      "Epoch 92/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9884 - loss: 0.0351 - val_accuracy: 0.8848 - val_loss: 0.5990\n",
      "Epoch 93/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9845 - loss: 0.0432 - val_accuracy: 0.8578 - val_loss: 0.6223\n",
      "Epoch 94/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9867 - loss: 0.0430 - val_accuracy: 0.8841 - val_loss: 0.5442\n",
      "Epoch 95/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9959 - loss: 0.0202 - val_accuracy: 0.8788 - val_loss: 0.5726\n",
      "Epoch 96/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.0271 - val_accuracy: 0.8664 - val_loss: 0.6713\n",
      "Epoch 97/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9621 - loss: 0.1027 - val_accuracy: 0.8829 - val_loss: 0.5431\n",
      "Epoch 98/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9918 - loss: 0.0276 - val_accuracy: 0.8859 - val_loss: 0.5472\n",
      "Epoch 99/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9932 - loss: 0.0250 - val_accuracy: 0.8732 - val_loss: 0.5970\n",
      "Epoch 100/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9839 - loss: 0.0424 - val_accuracy: 0.8822 - val_loss: 0.5740\n",
      "\n",
      " Time taken:120.07649898529053\n",
      "Test Accuracy: 0.8777441382408142\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0001\n",
    "training_epochs = 100\n",
    "batch_size = 100\n",
    "\n",
    "t1 = time.time()\n",
    "        \n",
    "# Construct model\n",
    "model = create_multilayer_perceptron()\n",
    "\n",
    "# Compile model with optimizer and loss function\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Load data\n",
    "train_features, train_labels, valid_features, valid_labels, test_features, test_labels = preprocess()\n",
    "\n",
    "# Train model\n",
    "model.fit(train_features, train_labels, epochs=training_epochs, batch_size=batch_size, validation_data=(valid_features, valid_labels))\n",
    "\n",
    "# Evaluate model accuracy\n",
    "test_loss, test_accuracy = model.evaluate(test_features, test_labels, verbose=0)\n",
    "t2 = time.time()\n",
    "        \n",
    "print('\\n Time taken:'+str(t2-t1))\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6498454-501e-4f61-aaf0-8e491b37e279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
