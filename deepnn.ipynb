{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "efcc88a8-7284-47cb-bcb2-da70ce475b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Create model with two hidden layers and an output layer\n",
    "def create_multilayer_perceptron():\n",
    "    # Network Parameters\n",
    "    n_hidden_1 = 256  # 1st layer number of features\n",
    "    n_hidden_2 = 256  # 2nd layer number of features\n",
    "    n_input = 2376    # data input\n",
    "    n_classes = 2     # number of classes\n",
    "\n",
    "    # Define the input layer\n",
    "    x = tf.keras.Input(shape=(n_input,))\n",
    "\n",
    "    # Hidden layers with ReLU activation\n",
    "    layer_1 = tf.keras.layers.Dense(n_hidden_1, activation='relu')(x)\n",
    "    layer_2 = tf.keras.layers.Dense(n_hidden_2, activation='relu')(layer_1)\n",
    "\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.keras.layers.Dense(n_classes)(layer_2)\n",
    "\n",
    "    # Create the model\n",
    "    model = tf.keras.Model(inputs=x, outputs=out_layer)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26a09927-09ff-4cfe-87d1-2ba1c3b2d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    with open('basecode/face_all.pickle', 'rb') as file:\n",
    "        pickle_obj = pickle.load(file)\n",
    "    features = pickle_obj['Features']\n",
    "    labels = pickle_obj['Labels']\n",
    "    train_x = features[0:21100] / 255\n",
    "    valid_x = features[21100:23765] / 255\n",
    "    test_x = features[23765:] / 255\n",
    "\n",
    "    labels = labels.T\n",
    "    train_y = np.zeros(shape=(21100, 2))\n",
    "    train_l = labels[0:21100]\n",
    "    valid_y = np.zeros(shape=(2665, 2))\n",
    "    valid_l = labels[21100:23765]\n",
    "    test_y = np.zeros(shape=(2642, 2))\n",
    "    test_l = labels[23765:]\n",
    "    for i in range(train_y.shape[0]):\n",
    "        train_y[i, train_l[i]] = 1\n",
    "    for i in range(valid_y.shape[0]):\n",
    "        valid_y[i, valid_l[i]] = 1\n",
    "    for i in range(test_y.shape[0]):\n",
    "        test_y[i, test_l[i]] = 1\n",
    "\n",
    "    return train_x, train_y, valid_x, valid_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3bad0940-d5de-487f-94fc-12872de63caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7041 - loss: 0.5672 - val_accuracy: 0.8094 - val_loss: 0.4312\n",
      "Epoch 2/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8270 - loss: 0.4048 - val_accuracy: 0.8191 - val_loss: 0.4092\n",
      "Epoch 3/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8466 - loss: 0.3572 - val_accuracy: 0.8525 - val_loss: 0.3570\n",
      "Epoch 4/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8586 - loss: 0.3347 - val_accuracy: 0.8623 - val_loss: 0.3359\n",
      "Epoch 5/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8657 - loss: 0.3184 - val_accuracy: 0.8623 - val_loss: 0.3292\n",
      "Epoch 6/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8709 - loss: 0.3087 - val_accuracy: 0.8079 - val_loss: 0.4209\n",
      "Epoch 7/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8683 - loss: 0.2993 - val_accuracy: 0.8735 - val_loss: 0.3147\n",
      "Epoch 8/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8724 - loss: 0.2939 - val_accuracy: 0.8709 - val_loss: 0.3197\n",
      "Epoch 9/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8844 - loss: 0.2834 - val_accuracy: 0.8814 - val_loss: 0.2996\n",
      "Epoch 10/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8926 - loss: 0.2648 - val_accuracy: 0.8848 - val_loss: 0.2898\n",
      "Epoch 11/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8939 - loss: 0.2608 - val_accuracy: 0.8537 - val_loss: 0.3450\n",
      "Epoch 12/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8839 - loss: 0.2750 - val_accuracy: 0.8559 - val_loss: 0.3463\n",
      "Epoch 13/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8930 - loss: 0.2585 - val_accuracy: 0.8859 - val_loss: 0.2865\n",
      "Epoch 14/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8934 - loss: 0.2590 - val_accuracy: 0.8863 - val_loss: 0.2840\n",
      "Epoch 15/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9039 - loss: 0.2372 - val_accuracy: 0.8612 - val_loss: 0.3213\n",
      "Epoch 16/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9021 - loss: 0.2332 - val_accuracy: 0.8859 - val_loss: 0.2935\n",
      "Epoch 17/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8983 - loss: 0.2467 - val_accuracy: 0.8841 - val_loss: 0.2818\n",
      "Epoch 18/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9063 - loss: 0.2291 - val_accuracy: 0.8852 - val_loss: 0.2906\n",
      "Epoch 19/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9060 - loss: 0.2288 - val_accuracy: 0.8829 - val_loss: 0.2845\n",
      "Epoch 20/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8998 - loss: 0.2400 - val_accuracy: 0.8841 - val_loss: 0.2842\n",
      "Epoch 21/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9163 - loss: 0.2111 - val_accuracy: 0.8901 - val_loss: 0.2757\n",
      "Epoch 22/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9102 - loss: 0.2136 - val_accuracy: 0.8811 - val_loss: 0.2913\n",
      "Epoch 23/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9103 - loss: 0.2194 - val_accuracy: 0.8803 - val_loss: 0.2961\n",
      "Epoch 24/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9198 - loss: 0.2029 - val_accuracy: 0.8844 - val_loss: 0.2901\n",
      "Epoch 25/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9181 - loss: 0.1995 - val_accuracy: 0.8882 - val_loss: 0.2886\n",
      "Epoch 26/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9146 - loss: 0.2093 - val_accuracy: 0.8649 - val_loss: 0.3396\n",
      "Epoch 27/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9212 - loss: 0.1942 - val_accuracy: 0.8923 - val_loss: 0.2848\n",
      "Epoch 28/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9340 - loss: 0.1774 - val_accuracy: 0.8694 - val_loss: 0.3350\n",
      "Epoch 29/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9286 - loss: 0.1826 - val_accuracy: 0.8826 - val_loss: 0.3067\n",
      "Epoch 30/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9337 - loss: 0.1714 - val_accuracy: 0.8901 - val_loss: 0.2902\n",
      "Epoch 31/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9264 - loss: 0.1792 - val_accuracy: 0.8874 - val_loss: 0.2905\n",
      "Epoch 32/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9273 - loss: 0.1814 - val_accuracy: 0.8814 - val_loss: 0.3128\n",
      "Epoch 33/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9361 - loss: 0.1653 - val_accuracy: 0.8863 - val_loss: 0.3084\n",
      "Epoch 34/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9398 - loss: 0.1578 - val_accuracy: 0.8604 - val_loss: 0.3681\n",
      "Epoch 35/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9274 - loss: 0.1819 - val_accuracy: 0.8660 - val_loss: 0.3526\n",
      "Epoch 36/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9430 - loss: 0.1481 - val_accuracy: 0.8923 - val_loss: 0.3064\n",
      "Epoch 37/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9434 - loss: 0.1471 - val_accuracy: 0.8807 - val_loss: 0.3162\n",
      "Epoch 38/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9452 - loss: 0.1446 - val_accuracy: 0.8931 - val_loss: 0.3117\n",
      "Epoch 39/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9488 - loss: 0.1369 - val_accuracy: 0.8867 - val_loss: 0.3246\n",
      "Epoch 40/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9491 - loss: 0.1367 - val_accuracy: 0.8750 - val_loss: 0.3438\n",
      "Epoch 41/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.1438 - val_accuracy: 0.8931 - val_loss: 0.3220\n",
      "Epoch 42/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9507 - loss: 0.1312 - val_accuracy: 0.8833 - val_loss: 0.3305\n",
      "Epoch 43/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9536 - loss: 0.1238 - val_accuracy: 0.8878 - val_loss: 0.3230\n",
      "Epoch 44/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9567 - loss: 0.1211 - val_accuracy: 0.8784 - val_loss: 0.3426\n",
      "Epoch 45/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9575 - loss: 0.1168 - val_accuracy: 0.8916 - val_loss: 0.3296\n",
      "Epoch 46/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9508 - loss: 0.1254 - val_accuracy: 0.8814 - val_loss: 0.3461\n",
      "Epoch 47/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1110 - val_accuracy: 0.8848 - val_loss: 0.3489\n",
      "Epoch 48/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.1038 - val_accuracy: 0.8795 - val_loss: 0.3458\n",
      "Epoch 49/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.1035 - val_accuracy: 0.8604 - val_loss: 0.4105\n",
      "Epoch 50/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9581 - loss: 0.1125 - val_accuracy: 0.8660 - val_loss: 0.3953\n",
      "Epoch 51/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1087 - val_accuracy: 0.8668 - val_loss: 0.4121\n",
      "Epoch 52/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.0989 - val_accuracy: 0.8672 - val_loss: 0.4373\n",
      "Epoch 53/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 0.0961 - val_accuracy: 0.8630 - val_loss: 0.4273\n",
      "Epoch 54/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9701 - loss: 0.0879 - val_accuracy: 0.8784 - val_loss: 0.3878\n",
      "Epoch 55/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9646 - loss: 0.0928 - val_accuracy: 0.8829 - val_loss: 0.3814\n",
      "Epoch 56/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9718 - loss: 0.0799 - val_accuracy: 0.8773 - val_loss: 0.3792\n",
      "Epoch 57/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9763 - loss: 0.0749 - val_accuracy: 0.8675 - val_loss: 0.4479\n",
      "Epoch 58/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9654 - loss: 0.0914 - val_accuracy: 0.8822 - val_loss: 0.4122\n",
      "Epoch 59/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9698 - loss: 0.0828 - val_accuracy: 0.8780 - val_loss: 0.4149\n",
      "Epoch 60/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9692 - loss: 0.0844 - val_accuracy: 0.8762 - val_loss: 0.4103\n",
      "Epoch 61/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9769 - loss: 0.0703 - val_accuracy: 0.8754 - val_loss: 0.4178\n",
      "Epoch 62/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9743 - loss: 0.0724 - val_accuracy: 0.8765 - val_loss: 0.4333\n",
      "Epoch 63/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9694 - loss: 0.0834 - val_accuracy: 0.8829 - val_loss: 0.4280\n",
      "Epoch 64/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9777 - loss: 0.0638 - val_accuracy: 0.8747 - val_loss: 0.4523\n",
      "Epoch 65/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9732 - loss: 0.0715 - val_accuracy: 0.8818 - val_loss: 0.4190\n",
      "Epoch 66/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9785 - loss: 0.0646 - val_accuracy: 0.8799 - val_loss: 0.4420\n",
      "Epoch 67/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9733 - loss: 0.0736 - val_accuracy: 0.8750 - val_loss: 0.4613\n",
      "Epoch 68/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9764 - loss: 0.0629 - val_accuracy: 0.8773 - val_loss: 0.4529\n",
      "Epoch 69/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9826 - loss: 0.0534 - val_accuracy: 0.8739 - val_loss: 0.4782\n",
      "Epoch 70/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9819 - loss: 0.0521 - val_accuracy: 0.8814 - val_loss: 0.4593\n",
      "Epoch 71/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9776 - loss: 0.0613 - val_accuracy: 0.8792 - val_loss: 0.4706\n",
      "Epoch 72/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9821 - loss: 0.0538 - val_accuracy: 0.8743 - val_loss: 0.4944\n",
      "Epoch 73/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.0465 - val_accuracy: 0.8739 - val_loss: 0.4812\n",
      "Epoch 74/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9835 - loss: 0.0490 - val_accuracy: 0.8668 - val_loss: 0.5119\n",
      "Epoch 75/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0438 - val_accuracy: 0.8762 - val_loss: 0.4833\n",
      "Epoch 76/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9848 - loss: 0.0431 - val_accuracy: 0.8750 - val_loss: 0.4913\n",
      "Epoch 77/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.0448 - val_accuracy: 0.8720 - val_loss: 0.5225\n",
      "Epoch 78/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9797 - loss: 0.0594 - val_accuracy: 0.8664 - val_loss: 0.5513\n",
      "Epoch 79/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9684 - loss: 0.0774 - val_accuracy: 0.8807 - val_loss: 0.4995\n",
      "Epoch 80/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9862 - loss: 0.0445 - val_accuracy: 0.8769 - val_loss: 0.5243\n",
      "Epoch 81/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9886 - loss: 0.0359 - val_accuracy: 0.8724 - val_loss: 0.5726\n",
      "Epoch 82/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9892 - loss: 0.0357 - val_accuracy: 0.8589 - val_loss: 0.6068\n",
      "Epoch 83/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9821 - loss: 0.0507 - val_accuracy: 0.8803 - val_loss: 0.5296\n",
      "Epoch 84/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9889 - loss: 0.0341 - val_accuracy: 0.8777 - val_loss: 0.5353\n",
      "Epoch 85/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9830 - loss: 0.0470 - val_accuracy: 0.8709 - val_loss: 0.6084\n",
      "Epoch 86/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9870 - loss: 0.0401 - val_accuracy: 0.8773 - val_loss: 0.5657\n",
      "Epoch 87/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9907 - loss: 0.0316 - val_accuracy: 0.8814 - val_loss: 0.5664\n",
      "Epoch 88/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9866 - loss: 0.0376 - val_accuracy: 0.8765 - val_loss: 0.5337\n",
      "Epoch 89/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9877 - loss: 0.0365 - val_accuracy: 0.8859 - val_loss: 0.5372\n",
      "Epoch 90/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0259 - val_accuracy: 0.8762 - val_loss: 0.6064\n",
      "Epoch 91/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9897 - loss: 0.0311 - val_accuracy: 0.8705 - val_loss: 0.6166\n",
      "Epoch 92/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9779 - loss: 0.0543 - val_accuracy: 0.8683 - val_loss: 0.6048\n",
      "Epoch 93/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9814 - loss: 0.0492 - val_accuracy: 0.8841 - val_loss: 0.5837\n",
      "Epoch 94/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0201 - val_accuracy: 0.8780 - val_loss: 0.5861\n",
      "Epoch 95/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9901 - loss: 0.0292 - val_accuracy: 0.8728 - val_loss: 0.6215\n",
      "Epoch 96/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.0471 - val_accuracy: 0.8559 - val_loss: 0.6340\n",
      "Epoch 97/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0253 - val_accuracy: 0.8826 - val_loss: 0.5990\n",
      "Epoch 98/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9935 - loss: 0.0213 - val_accuracy: 0.8762 - val_loss: 0.6130\n",
      "Epoch 99/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9888 - loss: 0.0304 - val_accuracy: 0.8750 - val_loss: 0.6249\n",
      "Epoch 100/100\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0208 - val_accuracy: 0.8735 - val_loss: 0.6581\n",
      "Test Accuracy: 0.8803936243057251\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0001\n",
    "training_epochs = 100\n",
    "batch_size = 100\n",
    "\n",
    "# Construct model\n",
    "model = create_multilayer_perceptron()\n",
    "\n",
    "# Compile model with optimizer and loss function\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Load data\n",
    "train_features, train_labels, valid_features, valid_labels, test_features, test_labels = preprocess()\n",
    "\n",
    "# Train model\n",
    "model.fit(train_features, train_labels, epochs=training_epochs, batch_size=batch_size, validation_data=(valid_features, valid_labels))\n",
    "\n",
    "# Evaluate model accuracy\n",
    "test_loss, test_accuracy = model.evaluate(test_features, test_labels, verbose=0)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ad39d6-a6f1-4e49-9431-a1b5479c2ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6498454-501e-4f61-aaf0-8e491b37e279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
