{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a89ede26-f9f6-4406-9fdc-0f8e19740a40",
   "metadata": {},
   "source": [
    "Face Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5602e43-de3b-4026-94c3-f5b7ad789158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from math import sqrt\n",
    "from numpy import exp\n",
    "import time\n",
    "import pickle\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30ebd2b9-6fa7-40e7-bf9b-f1c1bec411c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeWeights(n_in,n_out):\n",
    "    \"\"\"\n",
    "    # initializeWeights return the random weights for Neural Network given the\n",
    "    # number of node in the input layer and output layer\n",
    "\n",
    "    # Input:\n",
    "    # n_in: number of nodes of the input layer\n",
    "    # n_out: number of nodes of the output layer\n",
    "                            \n",
    "    # Output: \n",
    "    # W: matrix of random initial weights with size (n_out x (n_in + 1))\"\"\"\n",
    "    epsilon = sqrt(6) / sqrt(n_in + n_out + 1)\n",
    "    W = (np.random.rand(n_out, n_in + 1)*2* epsilon) - epsilon\n",
    "    return W\n",
    "    \n",
    "def sigmoid(z):\n",
    "    e = 1 / (1 + exp(-z))\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d81009d-9d18-4d8c-b7f2-438888b4060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnObjFunction(params, *args):\n",
    "    n_input, n_hidden, n_class, training_data, training_label, lambdaval = args\n",
    "\n",
    "    w1 = params[0:n_hidden * (n_input + 1)].reshape((n_hidden, (n_input + 1)))\n",
    "    w2 = params[(n_hidden * (n_input + 1)):].reshape((n_class, (n_hidden + 1)))\n",
    "    obj_val = 0\n",
    "\n",
    "    # Your code here\n",
    "    \n",
    "    n = training_data.shape[0]\n",
    "    # Feed forward code\n",
    "    w1_transpose = np.transpose(w1)\n",
    "    w2_transpose = np.transpose(w2)\n",
    "\n",
    "    input_bias = np.ones(shape=(n, 1), dtype = np.float64) # create input bias \n",
    "    biased_training_data = np.append(training_data, input_bias, axis=1) # Add input bias to training data\n",
    "    \n",
    "    aj = np.dot(biased_training_data, w1_transpose) # Product of W and input data\n",
    "    zj = sigmoid(aj) # Sigmoid of dot product\n",
    "    \n",
    "    hidden_bias = np.ones(shape=(zj.shape[0], 1), dtype = np.float64) \n",
    "    biased_zj = np.append(zj, hidden_bias, axis=1)\n",
    "    \n",
    "    bl = np.dot(biased_zj, w2_transpose)\n",
    "    ol = sigmoid(bl)\n",
    "    \n",
    "    # Labelling output\n",
    "    yl = np.zeros(shape=(n, 2), dtype = np.float64) # setting all output values to 0 initially\n",
    "    \n",
    "    for i in range(yl.shape[0]):   \n",
    "        for j in range(yl.shape[1]):\n",
    "            if j==training_label[i]:\n",
    "                yl[i][j] = 1.0             #set the class labeled value to 1 and rest to 0    \n",
    "        \n",
    "    # Error function\n",
    "    \n",
    "    p = yl*np.log(ol) # Element wise multiplication\n",
    "    q = (1-yl)*np.log(1-ol)\n",
    "    sum1 = np.sum(p+q)\n",
    "    constant = -1*n\n",
    "    error = sum1/constant # -(yl*log(ol)+(1-y1)*log(1-ol))/n\n",
    "    \n",
    "    # Regularised error function  \n",
    "    \n",
    "    w1_square_sum = np.sum(np.square(w1))\n",
    "    w2_square_sum = np.sum(np.square(w2))\n",
    "    sum2 = w1_square_sum + w1_square_sum                \n",
    "    reg_factor = (sum2*lambdaval)/(2*n)\n",
    "    reg_error = error + reg_factor\n",
    "    \n",
    "    obj_val = reg_error # Regularised error w.r.t lambda\n",
    "    \n",
    "    \n",
    "    # Make sure you reshape the gradient matrices to a 1D array. for instance if your gradient matrices are grad_w1 and grad_w2\n",
    "    # you would use code similar to the one below to create a flat array\n",
    "    # obj_grad = np.concatenate((grad_w1.flatten(), grad_w2.flatten()),0)\n",
    "    obj_grad = np.array([])\n",
    "    delta_l = ol-yl\n",
    "    delta_l_transpose = np.transpose(delta_l)\n",
    "    \n",
    "    grad_w2 = np.dot(delta_l_transpose, biased_zj)\n",
    "    \n",
    "    r = (1-biased_zj[:,0:n_hidden])*biased_zj[:,0:n_hidden]\n",
    "    s = np.dot(delta_l, w2[:,0:n_hidden])\n",
    "    rs = r*s\n",
    "    rs_transpose = np.transpose(rs)\n",
    "    grad_w1 = np.dot(rs_transpose, biased_training_data)\n",
    "    \n",
    "    # Regularised gradients\n",
    "    \n",
    "    reg_grad_w2 = (grad_w2 + (lambdaval*w2))/n\n",
    "    reg_grad_w1 = (grad_w1 + lambdaval*w1)/n\n",
    "    obj_grad = np.concatenate((reg_grad_w1.flatten(), reg_grad_w2.flatten()),0)\n",
    "    \n",
    "    return (obj_val, obj_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40136a4a-8372-4c87-9025-049666deff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnPredict(w1,w2,data):\n",
    "    labels = np.zeros(shape=(data.shape[0], 1))\n",
    "    #labels = np.zeros((data.shape[0],1))\n",
    "    # Your code here\n",
    "\n",
    "    # Feed forward code\n",
    "    input_bias = np.ones(shape=(data.shape[0],1), dtype=np.float64)\n",
    "    biased_data = np.append(data, input_bias, axis=1)\n",
    "    \n",
    "    w1_transpose = np.transpose(w1)\n",
    "    w2_transpose = np.transpose(w2)\n",
    "    \n",
    "    aj = np.dot(biased_data, w1_transpose)\n",
    "    zj = sigmoid(aj)\n",
    "    \n",
    "    hidden_bias = np.ones(shape=(zj.shape[0], 1), dtype=np.float64)\n",
    "    biased_zj = np.append(zj, hidden_bias, axis=1)\n",
    "    \n",
    "    bl= np.dot(biased_zj, w2_transpose)\n",
    "    ol = sigmoid(bl)\n",
    "    \n",
    "    for x in range(ol.shape[0]): # Label prediction\n",
    "        max_arg = np.argmax(ol[x])\n",
    "        labels[x] = max_arg\n",
    "        \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "509b4be5-a489-4f91-92e1-adc362239074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    pickle_obj = pickle.load(file=open('basecode/face_all.pickle', 'rb'))\n",
    "    features = pickle_obj['Features']\n",
    "    labels = pickle_obj['Labels']\n",
    "    train_x = features[0:21100] / 255\n",
    "    valid_x = features[21100:23765] / 255\n",
    "    test_x = features[23765:] / 255\n",
    "\n",
    "    labels = labels[0]\n",
    "    train_y = labels[0:21100]\n",
    "    valid_y = labels[21100:23765]\n",
    "    test_y = labels[23765:]\n",
    "    return train_x, train_y, valid_x, valid_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c41a974-9e6c-483d-afa5-0398bb8c8521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " lambda:0\n",
      "\n",
      " No of Hidden layers:4\n",
      "\n",
      " Training set Accuracy:86.48341232227487%\n",
      "\n",
      " Validation set Accuracy:85.29080675422139%\n",
      "\n",
      " Test set Accuracy:85.95760787282362%\n",
      "\n",
      " Time taken:11.431948184967041\n",
      "\n",
      " lambda:10\n",
      "\n",
      " No of Hidden layers:4\n",
      "\n",
      " Training set Accuracy:87.16587677725119%\n",
      "\n",
      " Validation set Accuracy:86.34146341463415%\n",
      "\n",
      " Test set Accuracy:86.63890991672974%\n",
      "\n",
      " Time taken:11.475628137588501\n",
      "\n",
      " lambda:20\n",
      "\n",
      " No of Hidden layers:4\n",
      "\n",
      " Training set Accuracy:84.51658767772511%\n",
      "\n",
      " Validation set Accuracy:83.07692307692308%\n",
      "\n",
      " Test set Accuracy:84.85995457986374%\n",
      "\n",
      " Time taken:9.423964738845825\n",
      "\n",
      " lambda:30\n",
      "\n",
      " No of Hidden layers:4\n",
      "\n",
      " Training set Accuracy:87.02843601895735%\n",
      "\n",
      " Validation set Accuracy:86.30393996247655%\n",
      "\n",
      " Test set Accuracy:86.41180923542771%\n",
      "\n",
      " Time taken:11.220985889434814\n",
      "\n",
      " lambda:40\n",
      "\n",
      " No of Hidden layers:4\n",
      "\n",
      " Training set Accuracy:85.5260663507109%\n",
      "\n",
      " Validation set Accuracy:84.09005628517824%\n",
      "\n",
      " Test set Accuracy:85.73050719152158%\n",
      "\n",
      " Time taken:11.006915092468262\n",
      "\n",
      " lambda:50\n",
      "\n",
      " No of Hidden layers:4\n",
      "\n",
      " Training set Accuracy:85.35071090047394%\n",
      "\n",
      " Validation set Accuracy:84.12757973733584%\n",
      "\n",
      " Test set Accuracy:85.35200605601817%\n",
      "\n",
      " Time taken:11.349169254302979\n",
      "\n",
      " lambda:60\n",
      "\n",
      " No of Hidden layers:4\n",
      "\n",
      " Training set Accuracy:86.26540284360189%\n",
      "\n",
      " Validation set Accuracy:84.953095684803%\n",
      "\n",
      " Test set Accuracy:86.4875094625284%\n",
      "\n",
      " Time taken:11.44831895828247\n",
      "\n",
      " lambda:0\n",
      "\n",
      " No of Hidden layers:8\n",
      "\n",
      " Training set Accuracy:85.33649289099526%\n",
      "\n",
      " Validation set Accuracy:83.41463414634146%\n",
      "\n",
      " Test set Accuracy:85.76835730507192%\n",
      "\n",
      " Time taken:9.425313234329224\n",
      "\n",
      " lambda:10\n",
      "\n",
      " No of Hidden layers:8\n",
      "\n",
      " Training set Accuracy:84.95260663507109%\n",
      "\n",
      " Validation set Accuracy:83.71482176360226%\n",
      "\n",
      " Test set Accuracy:85.38985616956852%\n",
      "\n",
      " Time taken:8.972306966781616\n",
      "\n",
      " lambda:20\n",
      "\n",
      " No of Hidden layers:8\n",
      "\n",
      " Training set Accuracy:85.17061611374407%\n",
      "\n",
      " Validation set Accuracy:83.78986866791745%\n",
      "\n",
      " Test set Accuracy:85.50340651021952%\n",
      "\n",
      " Time taken:10.632864952087402\n",
      "\n",
      " lambda:30\n",
      "\n",
      " No of Hidden layers:8\n",
      "\n",
      " Training set Accuracy:85.97630331753554%\n",
      "\n",
      " Validation set Accuracy:84.8405253283302%\n",
      "\n",
      " Test set Accuracy:85.91975775927327%\n",
      "\n",
      " Time taken:9.96405577659607\n",
      "\n",
      " lambda:40\n",
      "\n",
      " No of Hidden layers:8\n",
      "\n",
      " Training set Accuracy:85.25592417061611%\n",
      "\n",
      " Validation set Accuracy:83.60225140712946%\n",
      "\n",
      " Test set Accuracy:85.8440575321726%\n",
      "\n",
      " Time taken:9.492371082305908\n",
      "\n",
      " lambda:50\n",
      "\n",
      " No of Hidden layers:8\n",
      "\n",
      " Training set Accuracy:85.24644549763033%\n",
      "\n",
      " Validation set Accuracy:84.27767354596622%\n",
      "\n",
      " Test set Accuracy:85.69265707797123%\n",
      "\n",
      " Time taken:9.676738023757935\n",
      "\n",
      " lambda:60\n",
      "\n",
      " No of Hidden layers:8\n",
      "\n",
      " Training set Accuracy:85.87677725118483%\n",
      "\n",
      " Validation set Accuracy:86.22889305816135%\n",
      "\n",
      " Test set Accuracy:86.41180923542771%\n",
      "\n",
      " Time taken:11.486268281936646\n",
      "\n",
      " lambda:0\n",
      "\n",
      " No of Hidden layers:12\n",
      "\n",
      " Training set Accuracy:84.66350710900474%\n",
      "\n",
      " Validation set Accuracy:83.97748592870545%\n",
      "\n",
      " Test set Accuracy:85.2006056018168%\n",
      "\n",
      " Time taken:10.584090948104858\n",
      "\n",
      " lambda:10\n",
      "\n",
      " No of Hidden layers:12\n",
      "\n",
      " Training set Accuracy:84.51184834123224%\n",
      "\n",
      " Validation set Accuracy:82.81425891181988%\n",
      "\n",
      " Test set Accuracy:84.74640423921271%\n",
      "\n",
      " Time taken:9.438820838928223\n",
      "\n",
      " lambda:20\n",
      "\n",
      " No of Hidden layers:12\n",
      "\n",
      " Training set Accuracy:85.49289099526067%\n",
      "\n",
      " Validation set Accuracy:84.8780487804878%\n",
      "\n",
      " Test set Accuracy:85.80620741862226%\n",
      "\n",
      " Time taken:9.708928108215332\n",
      "\n",
      " lambda:30\n",
      "\n",
      " No of Hidden layers:12\n",
      "\n",
      " Training set Accuracy:85.28436018957346%\n",
      "\n",
      " Validation set Accuracy:83.63977485928706%\n",
      "\n",
      " Test set Accuracy:85.38985616956852%\n",
      "\n",
      " Time taken:9.868484258651733\n",
      "\n",
      " lambda:40\n",
      "\n",
      " No of Hidden layers:12\n",
      "\n",
      " Training set Accuracy:84.53554502369668%\n",
      "\n",
      " Validation set Accuracy:82.70168855534709%\n",
      "\n",
      " Test set Accuracy:84.82210446631339%\n",
      "\n",
      " Time taken:9.903517246246338\n",
      "\n",
      " lambda:50\n",
      "\n",
      " No of Hidden layers:12\n",
      "\n",
      " Training set Accuracy:85.0%\n",
      "\n",
      " Validation set Accuracy:82.92682926829268%\n",
      "\n",
      " Test set Accuracy:85.57910673732022%\n",
      "\n",
      " Time taken:10.064252138137817\n",
      "\n",
      " lambda:60\n",
      "\n",
      " No of Hidden layers:12\n",
      "\n",
      " Training set Accuracy:84.7867298578199%\n",
      "\n",
      " Validation set Accuracy:83.30206378986867%\n",
      "\n",
      " Test set Accuracy:85.12490537471612%\n",
      "\n",
      " Time taken:10.090198993682861\n",
      "\n",
      " lambda:0\n",
      "\n",
      " No of Hidden layers:16\n",
      "\n",
      " Training set Accuracy:84.86255924170617%\n",
      "\n",
      " Validation set Accuracy:83.41463414634146%\n",
      "\n",
      " Test set Accuracy:85.04920514761545%\n",
      "\n",
      " Time taken:9.218264818191528\n",
      "\n",
      " lambda:10\n",
      "\n",
      " No of Hidden layers:16\n",
      "\n",
      " Training set Accuracy:85.17535545023696%\n",
      "\n",
      " Validation set Accuracy:84.27767354596622%\n",
      "\n",
      " Test set Accuracy:85.27630582891749%\n",
      "\n",
      " Time taken:9.690582036972046\n",
      "\n",
      " lambda:20\n",
      "\n",
      " No of Hidden layers:16\n",
      "\n",
      " Training set Accuracy:84.34597156398105%\n",
      "\n",
      " Validation set Accuracy:82.85178236397749%\n",
      "\n",
      " Test set Accuracy:84.74640423921271%\n",
      "\n",
      " Time taken:9.50715684890747\n",
      "\n",
      " lambda:30\n",
      "\n",
      " No of Hidden layers:16\n",
      "\n",
      " Training set Accuracy:84.54976303317535%\n",
      "\n",
      " Validation set Accuracy:83.15196998123827%\n",
      "\n",
      " Test set Accuracy:85.0113550340651%\n",
      "\n",
      " Time taken:8.783023118972778\n",
      "\n",
      " lambda:40\n",
      "\n",
      " No of Hidden layers:16\n",
      "\n",
      " Training set Accuracy:86.521327014218%\n",
      "\n",
      " Validation set Accuracy:85.21575984990619%\n",
      "\n",
      " Test set Accuracy:86.07115821347465%\n",
      "\n",
      " Time taken:10.402265071868896\n",
      "\n",
      " lambda:50\n",
      "\n",
      " No of Hidden layers:16\n",
      "\n",
      " Training set Accuracy:85.30805687203792%\n",
      "\n",
      " Validation set Accuracy:83.67729831144464%\n",
      "\n",
      " Test set Accuracy:85.61695685087055%\n",
      "\n",
      " Time taken:9.416857719421387\n",
      "\n",
      " lambda:60\n",
      "\n",
      " No of Hidden layers:16\n",
      "\n",
      " Training set Accuracy:86.10426540284361%\n",
      "\n",
      " Validation set Accuracy:85.17823639774859%\n",
      "\n",
      " Test set Accuracy:86.14685844057533%\n",
      "\n",
      " Time taken:9.628277063369751\n",
      "\n",
      " lambda:0\n",
      "\n",
      " No of Hidden layers:20\n",
      "\n",
      " Training set Accuracy:83.61137440758294%\n",
      "\n",
      " Validation set Accuracy:82.4765478424015%\n",
      "\n",
      " Test set Accuracy:83.83800151400455%\n",
      "\n",
      " Time taken:9.455625057220459\n",
      "\n",
      " lambda:10\n",
      "\n",
      " No of Hidden layers:20\n",
      "\n",
      " Training set Accuracy:84.87677725118483%\n",
      "\n",
      " Validation set Accuracy:83.41463414634146%\n",
      "\n",
      " Test set Accuracy:85.31415594246783%\n",
      "\n",
      " Time taken:10.649721145629883\n",
      "\n",
      " lambda:20\n",
      "\n",
      " No of Hidden layers:20\n",
      "\n",
      " Training set Accuracy:85.40758293838863%\n",
      "\n",
      " Validation set Accuracy:83.82739212007505%\n",
      "\n",
      " Test set Accuracy:85.57910673732022%\n",
      "\n",
      " Time taken:10.881582021713257\n",
      "\n",
      " lambda:30\n",
      "\n",
      " No of Hidden layers:20\n",
      "\n",
      " Training set Accuracy:84.53554502369668%\n",
      "\n",
      " Validation set Accuracy:83.63977485928706%\n",
      "\n",
      " Test set Accuracy:84.51930355791067%\n",
      "\n",
      " Time taken:10.291780233383179\n",
      "\n",
      " lambda:40\n",
      "\n",
      " No of Hidden layers:20\n",
      "\n",
      " Training set Accuracy:84.92417061611374%\n",
      "\n",
      " Validation set Accuracy:83.30206378986867%\n",
      "\n",
      " Test set Accuracy:85.46555639666919%\n",
      "\n",
      " Time taken:11.682398796081543\n",
      "\n",
      " lambda:50\n",
      "\n",
      " No of Hidden layers:20\n",
      "\n",
      " Training set Accuracy:83.50236966824644%\n",
      "\n",
      " Validation set Accuracy:82.13883677298311%\n",
      "\n",
      " Test set Accuracy:84.40575321725964%\n",
      "\n",
      " Time taken:10.99145770072937\n",
      "\n",
      " lambda:60\n",
      "\n",
      " No of Hidden layers:20\n",
      "\n",
      " Training set Accuracy:85.18957345971565%\n",
      "\n",
      " Validation set Accuracy:84.39024390243902%\n",
      "\n",
      " Test set Accuracy:85.57910673732022%\n",
      "\n",
      " Time taken:10.695314884185791\n"
     ]
    }
   ],
   "source": [
    "train_data, train_label, validation_data, validation_label, test_data, test_label = preprocess()\n",
    "#  Train Neural Network\n",
    "n_input = train_data.shape[1]\n",
    "\n",
    "# set the number of nodes in output unit\n",
    "n_class = 2\n",
    "\n",
    "n_hidden_array = [4,8,12,16,20]\n",
    "\n",
    "for x in n_hidden_array:\n",
    "    for y in range(0,70,10):\n",
    "        \n",
    "        # set the number of nodes in hidden unit (not including bias unit)\n",
    "        n_hidden = x # values - 4,8,12,16,20\n",
    "\n",
    "        # set the regularization hyper-parameter\n",
    "        lambdaval = y # values - 0 to 60, 10\n",
    "        \n",
    "        # Note current time\n",
    "        t1 = time.time()\n",
    "        \n",
    "        # initialize the weights into some random matrices\n",
    "        initial_w1 = initializeWeights(n_input, n_hidden);\n",
    "        initial_w2 = initializeWeights(n_hidden, n_class);\n",
    "        # unroll 2 weight matrices into single column vector\n",
    "        initialWeights = np.concatenate((initial_w1.flatten(), initial_w2.flatten()),0)\n",
    "        \n",
    "        args = (n_input, n_hidden, n_class, train_data, train_label, lambdaval)\n",
    "\n",
    "        #Train Neural Network using fmin_cg or minimize from scipy,optimize module. Check documentation for a working example\n",
    "        opts = {'maxiter' :50}    # Preferred value.\n",
    "\n",
    "        nn_params = minimize(nnObjFunction, initialWeights, jac=True, args=args,method='CG', options=opts)\n",
    "        params = nn_params.get('x')\n",
    "        #Reshape nnParams from 1D vector into w1 and w2 matrices\n",
    "        w1 = params[0:n_hidden * (n_input + 1)].reshape( (n_hidden, (n_input + 1)))\n",
    "        w2 = params[(n_hidden * (n_input + 1)):].reshape((n_class, (n_hidden + 1)))\n",
    "\n",
    "        print(\"\\n lambda:\"+str(lambdaval))\n",
    "        print(\"\\n No of Hidden layers:\"+str(n_hidden))\n",
    "        #Test the computed parameters\n",
    "        predicted_label = nnPredict(w1,w2,train_data)\n",
    "        #find the accuracy on Training Dataset\n",
    "        print('\\n Training set Accuracy:' + str(100*np.mean((predicted_label == train_label.reshape(train_label.shape[0], 1)).astype(float))) + '%')\n",
    "        predicted_label = nnPredict(w1,w2,validation_data)\n",
    "        #find the accuracy on Validation Dataset\n",
    "        print('\\n Validation set Accuracy:' + str(100*np.mean((predicted_label == validation_label.reshape(validation_label.shape[0], 1)).astype(float))) + '%')\n",
    "        predicted_label = nnPredict(w1,w2,test_data)\n",
    "        #find the accuracy on Validation Dataset\n",
    "        print('\\n Test set Accuracy:' +  str(100*np.mean((predicted_label == test_label.reshape(test_label.shape[0], 1)).astype(float))) + '%')\n",
    "        \n",
    "        t2 = time.time()\n",
    "        \n",
    "        print('\\n Time taken:'+str(t2-t1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f6040-8c39-444c-aab1-e0563630422a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
